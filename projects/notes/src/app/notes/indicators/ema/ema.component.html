<app-bar-series-select label="example data" (selectionChange)="dataSelectionChanged($event)"></app-bar-series-select>
<mb-linear-chart [dataSeries]="dataSelection.data" [title]="dataSelection.mnemonic"></mb-linear-chart>
<br/>
<hr />
<h1>Another view from Risk Metrics</h1>
<div style="width:100%">
  The exponential smoothing is defined by the following recurrent relation
  <mb-kd>{{"\\tag{1.1}\\begin{cases}
    m_{1}=x_{1} & k=1\\\\
    m_{k}=\\alpha x_{k}+(1-\\alpha)m_{k-1}=\\alpha x_{k}+\\lambda m_{k-1} & k\\gt 1
    \\end{cases}"}}</mb-kd>
  where <mb-ki>{{"\\lambda=1-\\alpha"}}</mb-ki>.

  This recurrence also defines a weighted average with the following weights
  <mb-kd>{{"\\tag{1.2}m_{k}=\\sum_{i=1}^{k}w_{k,i}x_{i},\\ \\ w_{k,i}=\\begin{cases}
    \\lambda^{k} & i=1\\\\
    \\alpha\\lambda^{k-i} & i \\gt 1
    \\end{cases}"}}</mb-kd>

  The weights decrease exponentially with the decay factor <mb-ki>{{"\\nu=-ln(\\lambda)"}}</mb-ki>,
  which gave the name for this smoothing:
  <mb-kd>{{"\\tag{1.3}\\begin{cases}
    \\frac{w_{k,i}}{w_{k,i+1}}=\\lambda=e^{-\\nu} & i=k-1,\\,\\ldots,\\,2\\\\
    \\frac{w_{k,1}}{w_{k,2}}=\\frac{\\lambda}{\\alpha} & i=1
    \\end{cases}"}}</mb-kd>

  The weight <mb-ki>{{"w_{k,1}"}}</mb-ki> in the previous equation does not follow the same exponential rule.
  For <mb-ki>{{"\\lambda>\\frac{1}{2}"}}</mb-ki> it is even not the smallest one.

  The pure exponential average can be defined as
  <mb-kd>{{"\\tag{1.4}m_{k}=\\frac{S_{k}}{N_{k}},
    \\ S_{k}=\\sum_{i=1}^{k}\\lambda^{k-i}x_{i},\\ N_{k}=\\sum_{i=1}^{k}\\lambda^{k-i}"}}</mb-kd>

  The above equation can be written as recurrent relations:
  <mb-kd>{{"\\tag{1.5}S_{k}=x_{k}+\\lambda S_{k-1},\\ N_{k}=1+\\lambda N_{k-1}"}}</mb-kd>

  Using these equations, it is easy to derive a recurrence for the mean value
  <mb-kd>{{"\\begin{align}
    \\tag*{}m_{k} &= \\frac{x_{k}+\\lambda S_{k-1}}{N_{k}}\\\\
    \\tag*{}&= \\frac{x_{k}}{N_{k}}+\\frac{\\lambda N_{k-1}}{N_{k}}m_{k-1}\\\\
    \\tag*{}&= m_{k-1}+\\frac{x_{k}}{N_{k}}+\\left(\\frac{\\lambda N_{k-1}}{N_{k}}-1\\right)m_{k-1}\\\\
    \\tag*{}&= m_{k-1}+\\frac{x_{k}}{N_{k}}-\\frac{m_{k-1}}{N_{k}}\\\\
    \\tag{1.6}&= m_{k-1}+\\frac{x_{k}-m_{k-1}}{N_{k}}
    \\end{align}"}}</mb-kd>

  Finally,
  <mb-kd>{{"\\tag{1.7}m_{k}=m_{k-1}+\\frac{\\delta_{k}}{N_{k}},\\ \\delta_{k}=x_{k}-m_{k-1}"}}</mb-kd>
  
  The equations (1.7) are remarkably similar to (sma 1.1) - (sma 1.3) in the
  <a href="/3">Simple Moving Average</a> article.
  <mb-kd>{{"\\tag{sma 1.1}m_{k}=m_{k-1}+\\frac{\\delta_{k}-\\delta_{k-n}}{N_{k}}"}}</mb-kd>
  <mb-kd>{{"\\tag{sma 1.2}\\begin{cases}
    \\delta_{l}=x_{l}-m_{k-1} & l\\gt 0\\\\
    \\delta_{l}=0 & l\\leq0
    \\end{cases}"}}</mb-kd>
  <mb-kd>{{"\\tag{sma 1.3}\\begin{cases}
    N_{k}=n & k\\geq n\\\\
    N_{k}=k & k\\lt n
    \\end{cases}"}}</mb-kd>
  
  The smoothing length is well defined in the simple average.
  It is the norm <mb-ki>{{"N_{k}"}}</mb-ki> from (sma 1.3). The norm (1.5) is the
  generalization of (sma 1.3) and defines the effective smoothing length for the exponential average:
  <mb-kd>{{"\\tag{1.8}N_{k}=\\frac{1-\\lambda^{k}}{1-\\lambda}=\\frac{1-\\lambda^{k}}{\\alpha}"}}</mb-kd>

  This norm accounts for 100% of all weights. At sufficiently large <mb-ki>k</mb-ki>
  <mb-kd>{{"\\tag{1.9}\\frac{1}{N_{k}}\\rightarrow\\frac{1}{N_{\\infty}}=\\alpha"}}</mb-kd>
  and
  <mb-kd>{{"\\tag{1.10}\\frac{\\lambda^{k-i}}{N_{k}}\\approx w_{k,i}"}}</mb-kd>

  Therefore both definitions of exponential smoothing coincide for large <mb-ki>k</mb-ki>.
  Actually the difference between the two definitions tends to zero as <mb-ki>{{"\\lambda^{k}"}}</mb-ki>.
  <p></p>
  The definition (1.8) seems to be natural, however historically the smoothing period <mb-ki>P</mb-ki> for the
  exponential smoothing (1.1) is defined as
  <mb-kd>{{"\\tag{1.11}\\alpha=\\frac{2}{P+1}"}}</mb-kd>
  These two definitions related as
  <mb-kd>{{"\\tag{1.12}N_{k}=\\frac{P+1}{2}\\left[1-\\left(\\frac{P-1}{P+1}\\right)^{k}\\right]\\approx\\frac{P+1}{2}"}}</mb-kd>

  In RiskMetrics [<a href="http://www.wu.ac.at/executiveeducation/institutes/banking/sbwl/lvs_ws/vk4/rrmfinal.pdf">does not exist</a>]
  the effective averaging length <mb-ki>L</mb-ki> is defined as
  <mb-kd>{{"\\tag*{}\\frac{N_{L}}{N_{\\infty}}=0.999=1-\\epsilon"}}</mb-kd>
  Therefore
  <mb-kd>{{"\\begin{align}
    \\tag*{}1-\\lambda^{L} &= 1-\\epsilon\\\\
    \\tag*{}\\lambda^{L} &= \\epsilon
    \\end{align}"}}</mb-kd>
  or
  <mb-kd>{{"\\tag{1.13}\\lambda=\\epsilon^{\\frac{1}{L}}"}}</mb-kd>
  This length is related to the natural length as
  <mb-kd>{{"\\tag{1.14}L=\\frac{ln(\\epsilon)}{ln(\\lambda)}=\\frac{ln(\\epsilon)}{ln(1-\\frac{1}{N_{\\infty}})}"}}</mb-kd>
  For <mb-ki>{{"N_{\\infty} >> 1"}}</mb-ki>, we get <mb-ki>{{"L \\approx 6.9\\; N_{\\infty}"}}</mb-ki>.

  In particular, for <mb-ki>\lambda=0.94</mb-ki> [<a
    href="http://www.wu.ac.at/executiveeducation/institutes/banking/sbwl/lvs_ws/vk4/rrmfinal.pdf">does not exist</a>],
  the above definitions give the following values: <mb-ki>L=112</mb-ki>, <mb-ki>P=33</mb-ki>,
  <mb-ki>{{"N_{\\infty}=17"}}</mb-ki>.

  A couple of specific cases are also worth mentioning.
  For <mb-ki>{{"N_{\\infty}=P=1\\ \\ lambda=0"}}</mb-ki> - no averaging; and
  for <mb-ki>L=1\ \ \lambda=0.001</mb-ki>.

  The values of all definitions for selected <mb-ki>\lambda</mb-ki> are collected in the table below.
</div>
<p></p>

<table>
  <thead>
    <tr>
      <th>
        <mb-ki>\lambda</mb-ki>
      </th>
      <th>
        <mb-ki>L</mb-ki>
      </th>
      <th>
        <mb-ki>P</mb-ki>
      </th>
      <th>
        <mb-ki>{{"N_{\\infty}"}}</mb-ki>
      </th>
      <th>&nbsp;Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> 0 </td>
      <td> 0 </td>
      <td> 1 </td>
      <td> 1 </td>
      <td>No averaging</td>
    </tr>
    <tr>
      <td> 0.001 </td>
      <td> 1 </td>
      <td> 1.002 </td>
      <td> 1.001 </td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td> 0.5 </td>
      <td> 10 </td>
      <td> 3 </td>
      <td> 2 </td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td> 0.75 </td>
      <td> 24 </td>
      <td> 7 </td>
      <td> 4 </td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td> 0.875 </td>
      <td> 52 </td>
      <td> 15 </td>
      <td> 8 </td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td> 0.94 </td>
      <td> 112 </td>
      <td> 33 </td>
      <td> 17 </td>
      <td>&nbsp;RiskMetrix</td>
    </tr>
  </tbody>
</table>

<h1 class="counter-skip">References</h1>
<div id='Ehlers2001'>Ehlers, John F. (2001). <em>Rocket Science for Traders: Digital Signal Processing
    Applications</em>. Wiley, 2001. ISBN:9780471405672 <a
    href="https://books.google.nl/books?id=K9F1rgEACAAJ">online</a> <a href="offline/ehlers2001.pdf">offline</a></div>
<div id='Ehlers2004'>Ehlers, John F. (2004). <em>Cybernetic Analysis for Stocks and Futures: Cutting-Edge DSP Technology
    to Improve Your Trading</em>. Wiley, 2004. ISBN:9780471463078 <a
    href="https://books.google.nl/books?id=Wj6sNAEACAAJ">online</a> <a href="offline/ehlers2004.pdf">offline</a></div>
<div id='Ehlers2013'>Ehlers, John F. (2013). <em>Cycle Analytics for Traders + Downloadable Software: Advanced Technical
    Trading Concepts</em>. John Wiley &amp; Sons, 2013. ISBN:9781118728604 <a
    href="https://books.google.nl/books?id=2z9VAgAAQBAJ">online</a> <a href="offline/ehlers2013.pdf">offline</a></div>
<div id='Ehlers1992'>Ehlers, John F. (1992). <em>MESA and Trading Market Cycles</em>. Wiley, 1992. ISBN:9780471549437 <a
    href="https://books.google.nl/books?id=0UUUAQAAMAAJ">online</a> <a href="offline/ehlers1992.pdf">offline</a></div>
<div id='Ehlers2010'>Ehlers, John F. and Way, Rick (2010, November). <em>Zero Lag (Well, Almost)</em>. Technical
  Analysis of Stocks &amp; Commodities, vol. 28 (11), pp. 30-35. ISSN:0738-3355 <a
    href="http://store.traders.com/stcov283zela.html">online</a> <a
    href="offline/tasc_v28_2010_11_pp30-35_John_Ehlers_Ric_Way-Zero_Lag_(Well_Almost).pdf">offline</a></div>
